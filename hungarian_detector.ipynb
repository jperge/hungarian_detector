{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify nationality from names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, re, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(99)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Activation, Dropout, LSTM, BatchNormalization, GRU, Bidirectional\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(data, outcomes):\n",
    "\n",
    "    np.random.seed(99)\n",
    "    shuffled_ix = np.random.permutation(len(data))\n",
    "    data = data[shuffled_ix,:]\n",
    "    outcomes = outcomes[shuffled_ix]\n",
    "\n",
    "    ## split data to train/validation:\n",
    "    validation_split = 0.2\n",
    "    nb_validation_samples = int(validation_split * len(data))\n",
    "\n",
    "    x_train = data[:-nb_validation_samples,:]\n",
    "    y_train = outcomes[:-nb_validation_samples]\n",
    "    x_val = data[-nb_validation_samples:,:]\n",
    "    y_val = outcomes[-nb_validation_samples:]\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val\n",
    "\n",
    "def sentence_to_ix(names, seq_len=30):\n",
    "    \n",
    "    unknown_ix = vocab_size\n",
    "    \n",
    "    #split up names\n",
    "    split_names = [list(str(name)) for name in list(names)]\n",
    "    \n",
    "    #convert medical terms to indices:\n",
    "    char_ixs = [[char_to_ix[character] for character in name] for name in split_names]\n",
    "\n",
    "    #shorten or pad sequences at seq_len:\n",
    "    trms_ixs = sequence.pad_sequences(char_ixs, maxlen=seq_len, value=unknown_ix)    \n",
    "    \n",
    "    return np.array(trms_ixs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321385, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nams = pd.read_csv('./create_data/names_dataset.csv')\n",
    "nams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>given</th>\n",
       "      <th>hun</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petrovics</td>\n",
       "      <td>bernadett</td>\n",
       "      <td>1</td>\n",
       "      <td>petrovics,bernadett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balatoni</td>\n",
       "      <td>irma</td>\n",
       "      <td>1</td>\n",
       "      <td>balatoni,irma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rusznyak</td>\n",
       "      <td>valeria</td>\n",
       "      <td>1</td>\n",
       "      <td>rusznyak,valeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paternina</td>\n",
       "      <td>tyanna</td>\n",
       "      <td>0</td>\n",
       "      <td>paternina,tyanna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stommes</td>\n",
       "      <td>evett</td>\n",
       "      <td>0</td>\n",
       "      <td>stommes,evett</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      family      given  hun            full_name\n",
       "0  petrovics  bernadett    1  petrovics,bernadett\n",
       "1   balatoni       irma    1        balatoni,irma\n",
       "2   rusznyak    valeria    1     rusznyak,valeria\n",
       "3  paternina     tyanna    0     paternina,tyanna\n",
       "4    stommes      evett    0        stommes,evett"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4340681 total characters and 28 unique characters in your data.\n"
     ]
    }
   ],
   "source": [
    "#obtain character set:\n",
    "allnames = []\n",
    "for name in nams.full_name:\n",
    "    allnames += name\n",
    "chars = list(set(allnames))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print('There are %d total characters and %d unique characters in your data.' % (len(allnames), len(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max character length 27 is set as sequence length\n"
     ]
    }
   ],
   "source": [
    "lens = np.array([len(i) for i in nams.full_name])\n",
    "seq_len = lens.max()\n",
    "print('max character length {} is set as sequence length'.format(seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: ',', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'j', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'q', 19: 'r', 20: 's', 21: 't', 22: 'u', 23: 'v', 24: 'w', 25: 'x', 26: 'y', 27: 'z'}\n"
     ]
    }
   ],
   "source": [
    "char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "print(ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape=(seq_len,), dtype='int32', name='main_input')\n",
    "# Embedding layer to encode the input sequence into 50-dimensional embedding vectors.\n",
    "x = Embedding(output_dim=50, input_dim=vocab_size+1, input_length=seq_len)(main_input)\n",
    "x = LSTM(32)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=main_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 27, 50)            1450      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                10624     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,107\n",
      "Trainable params: 12,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optim = Adam(lr=0.002, beta_1=0.85)\n",
    "model.compile(optimizer=adam_optim, loss='binary_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sentence_to_ix(nams.full_name, seq_len=seq_len)\n",
    "outcomes = nams.hun.values\n",
    "x_train, x_val, y_train, y_val = data_prep(data, outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 257108 samples, validate on 64277 samples\n",
      "Epoch 1/3\n",
      "257108/257108 [==============================] - 16s 62us/step - loss: 0.1028 - acc: 0.9617 - val_loss: 0.0816 - val_acc: 0.9701\n",
      "Epoch 2/3\n",
      "257108/257108 [==============================] - 16s 62us/step - loss: 0.0800 - acc: 0.9720 - val_loss: 0.0632 - val_acc: 0.9782\n",
      "Epoch 3/3\n",
      "257108/257108 [==============================] - 16s 62us/step - loss: 0.0639 - acc: 0.9790 - val_loss: 0.0493 - val_acc: 0.9838\n",
      "elapsed training time: 48.16281175613403 sec\n",
      "train roc: 0.9977544221428531\n",
      "test roc: 0.9976069324322784\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "model.fit(x_train, y_train, epochs = 3, batch_size = 512, shuffle=True, validation_data=(x_val, y_val), verbose=1)\n",
    "tend = time.time()\n",
    "print('elapsed training time: {} sec'.format(tend-tstart))\n",
    "\n",
    "y_pred = model.predict(x_train)\n",
    "print('train roc: {}'.format(roc_auc_score(y_train, y_pred)))\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "print('test roc: {}'.format(roc_auc_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   American       0.99      0.98      0.98     32338\n",
      "  Hungarian       0.98      0.99      0.98     31939\n",
      "\n",
      "avg / total       0.98      0.98      0.98     64277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array(y_pred>0.75).astype('int')\n",
    "target_names = ['American', 'Hungarian']\n",
    "print(classification_report(y_val, yhat, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31699,   639],\n",
       "       [  375, 31564]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93117267]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = sentence_to_ix(['perge,janos'], seq_len=seq_len)\n",
    "model.predict(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.16900390e-08]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = sentence_to_ix(['robertson,kelsea'], seq_len=seq_len)\n",
    "model.predict(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.83647567]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = sentence_to_ix(['kovacs,kelsea'], seq_len=seq_len)\n",
    "model.predict(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.67025494e-08]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = sentence_to_ix(['robertson,janos'], seq_len=seq_len)\n",
    "model.predict(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.45191976e-05]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = sentence_to_ix(['tseng,leo'], seq_len=seq_len)\n",
    "model.predict(aa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
